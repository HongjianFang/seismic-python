#! /usr/bin/env python

from gazelle.datascope import Database
import seispy as sp
from obspy.core import Stream, read
from obspy.core.utcdatetime import UTCDateTime
from argparse import ArgumentParser
from multiprocessing import Process, Queue
import os
import shutil
import tempfile

def parse_args():
    parser = ArgumentParser()
    parser.add_argument("database", type=str, help="database")
    parser.add_argument("-n", "--n_threads",
                        type=int,
                        help="number of threads")
    return parser.parse_args()

def inputter(args):
    for record in args.detections["grouped"].iter_record():
        sta, chan = record.getv("sta", "chan")
        try:
            station = args.database.virtual_network.stations[sta]
        except KeyError:
            continue
        yield (station, chan)

def main_processor(obj, args):
    station, chan = obj
    channel_set = station.get_channel_set(chan)
    sortd = args.detections["sorted"]
    groupd = args.detections["grouped"]
    groupd.record = groupd.find("sta =~ /%s/ && chan =~ /%s/"
                                % (station.name, chan))
    rnge = groupd.get_range()
    sortd.record = rnge[0]
    time = UTCDateTime(sortd.getv("time")[0])
    buffr = Queue(3)
    buffer_proc = Process(target=buffer_data,
                          args=(buffr,
                                args.database,
                                station,
                                channel_set,
                                time))
    buffer_proc.daemon = True
    buffer_proc.start()
    gather0 = buffr.get()
    for sortd.record in range(rnge[0], rnge[1]):
        time = UTCDateTime(sortd.getv("time")[0])
        starttime = gather0.stats.starttime + 4.
        endtime = gather0.stats.endtime - 16.0
        if time < starttime:
            continue
        elif time > endtime:
            brk = False
            while time > endtime:
                gather0 = buffr.get()
                if gather0 is None:
                    brk = True
                    break
                starttime = gather0.stats.starttime + 4.
                endtime = gather0.stats.endtime - 16.0
            if brk is True:
                print "no more data"
                break
        gather = gather0.copy()
        gather.trim(starttime=time - 4.0, endtime=time + 16.0)
        try:
            detection = gather.detect_swave(time)
        except Exception:
            continue
        if detection is not None:
            yield detection
    buffer_proc.terminate()
    buffer_proc.join()

def get_24h_gather(database, station, channel_set, time):
    t0 = time
    time.hour, time.minute, time.second, time.microsecond = 0, 0, 0, 0
    if time + 86400 - t0 < 16.:
        gather = database.get_gather3c(station,
                                     channel_set,
                                     t0 - 4.,
                                     time + 2 * 86400)
    else:
        gather = database.get_gather3c(station,
                                       channel_set,
                                       time,
                                       time + 86400.)
    gather.detrend("linear")
    gather.filter("bandpass", freqmin=3.0, freqmax=10.0)
    return gather

def buffer_data(buffr, database, station, channel_set, time):
    year = time.year
    time.hour, time.minute, time.second, time.microsecond = 0, 0, 0, 0
    while time.year == year:
        try:
            gather = get_24h_gather(database, station, channel_set, time)
        except IOError:
            print "no data", station, channel_set, time
            time.julday += 1
            continue
        except NotImplementedError:
            print "silently continue"
            time.julday += 1
            continue
        buffr.put(gather)
        time.julday += 1
    buffr.put(None)
    buffr.close()

def outputter(detection, tbl):
    if detection is not None:
        print "S-wave:", detection.station.name, detection.channel.code, detection.time
        tbl.record = tbl.addnull()
        tbl.putv(("sta", detection.station.name),
                 ("chan", detection.channel.code),
                 ("time", detection.time.timestamp),
                 ("snr", detection.snr),
                 ("state", "S"),
                 ("filter", "BP 3-10"))

def init_args(args):
    args.database = Database(args.database, mode="r+")
    view = args.database.tables["detection"].subset("state =~ /P/")
    _tmp = view.sort(("sta", "chan", "time")); view.free(); view = _tmp
    args.detections = {"sorted": view}
    args.detections["grouped"] = args.detections["sorted"].group(("sta", "chan"))
    _ = args.database.wfdisc
    return args

def main():
    args = parse_args()
    args = init_args(args)
    extra_args = {"input_init_args": (args,),
                  "main_init_args": (args,),
                  "output_init_args": (args.database.tables["detection"],)}
    if args.n_threads is not None:
        n_threads = args.n_threads
    else:
        n_threads = 1
    config_params = {"n_threads": n_threads}
    mtp = sp.util.MultiThreadProcess(inputter,
                                     main_processor,
                                     outputter,
                                     extra_args=extra_args,
                                     config_params=config_params)
    mtp.start()
    outfile.close()
    args.detections["sorted"].free()
    args.detections["grouped"].free()

if __name__ == "__main__":
    main()
